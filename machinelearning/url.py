import requests
from bs4 import BeautifulSoup
import pandas as pd
import os

# URL principale du site Worldometer
URL = "https://www.worldometers.info/coronavirus/"

# User-Agent pour √©viter le blocage
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

# Liste des noms de continents et autres entr√©es √† exclure
EXCLUDED_ENTITIES = ["World", "Asia", "Europe", "North America", "South America", "Oceania", "Africa", "Total",
                     "MS Zaandam", "Diamond Princess"]

def get_country_urls():
    """R√©cup√®re la liste des pays et leurs liens en FOR√áANT le format correct."""
    try:
        response = requests.get(URL, headers=HEADERS, timeout=10)
        response.raise_for_status()
    except requests.RequestException as e:
        print(f"‚ùå Erreur de connexion : {e}")
        return

    soup = BeautifulSoup(response.text, 'html.parser')

    country_links = []
    table = soup.find("table", id="main_table_countries_today")

    if table:
        for row in table.find("tbody").find_all("tr"):
            columns = row.find_all("td")
            if columns and len(columns) > 1:
                country_name = columns[1].text.strip()

                # Exclure les continents et entr√©es non pertinentes
                if country_name in EXCLUDED_ENTITIES or len(country_name) < 2:
                    continue

                # ‚úÖ FORCER le bon format d'URL
                country_slug = country_name.lower().replace(" ", "-").replace(".", "").replace(",", "").replace("(", "").replace(")", "").replace("‚Äô", "").replace("'", "")
                country_url = f"https://www.worldometers.info/coronavirus/country/{country_slug}/"

                country_links.append([country_name, country_url])

    # ‚úÖ Supprime l'ancien fichier avant d'√©crire les nouvelles donn√©es
    if os.path.exists("data/country_urls.csv"):
        os.remove("data/country_urls.csv")

    # ‚úÖ Enregistrement des URLs dans un fichier CSV
    df = pd.DataFrame(country_links, columns=["Country", "URL"])
    df.to_csv("data/country_urls.csv", index=False)
    print("\n‚úÖ Fichier 'data/country_urls.csv' g√©n√©r√© avec succ√®s !")

    # ‚úÖ V√©rification des 10 premi√®res URLs g√©n√©r√©es
    print("\nüîé V√©rification des 10 premi√®res URLs :")
    for i in range(min(10, len(country_links))):
        print(f"üåç {country_links[i][0]} ‚Üí {country_links[i][1]}")

# ‚úÖ Ex√©cuter la r√©cup√©ration des URLs
get_country_urls()
